{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c1cbe2",
   "metadata": {},
   "source": [
    " ## Etapa 2 — Tratamento (limpeza e padronização)\n",
    " Agora eu pego a tabela bruta (titles_raw) e crio tabelas limpas e estruturadas:\n",
    " - titles_clean: base padronizada (snake_case implícito nas saídas e textos em minúsculos).\n",
    " - titles_by_country: relacionamento título × país (explode coluna multivalor country).\n",
    " - titles_by_genre: relacionamento título × gênero (explode listed_in).\n",
    "\n",
    " Nesta etapa eu uso bastante SQL no SQLite por ser leve e repetir a lógica de produção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91a87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "CWD = Path.cwd().resolve()\n",
    "PROJECT_DIR = CWD.parent if CWD.name.lower() in {\"scr\", \"src\", \"notebooks\"} else CWD\n",
    "\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "SQLITE_PATH = DATA_DIR / \"netflix.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f736f",
   "metadata": {},
   "source": [
    "Conexão com SQLite\n",
    " Abro/uso o banco local netflix.db. É prático para testes e depois dá para migrar\n",
    " a mesma lógica para outro SGBD se eu quiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13f91197",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(SQLITE_PATH.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91793d91",
   "metadata": {},
   "source": [
    "Criação da tabela titles_clean\n",
    " Aqui eu:\n",
    " - Padronizo texto: lower(trim(...)) para ficar em minúsculas e sem espaços nas pontas.\n",
    " - Preencho nulos:\n",
    "   - country: viro \"unknown\" quando vazio/nulo (facilita contagens).\n",
    "   - rating: viro \"not_rated\" (padroniza o \"sem classificação\").\n",
    " - Datas:\n",
    "   - \"date_added\" vem em texto (ex.: \"Sep 9, 2019\"). Uso substr + instr + printf para\n",
    "     converter no formato \"YYYY-MM-DD\" aceito pelo date(). Assim eu posso filtrar por período.\n",
    " - Números:\n",
    "   - release_year vira INTEGER.\n",
    " - Duração:\n",
    "   - duration original vira duas colunas:\n",
    "     - duration_value\n",
    "     - duration_unit  (min/season)\n",
    "   Isso separa a medida do valor, deixando as análises muito mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df1e5801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles_clean criada\n"
     ]
    }
   ],
   "source": [
    "create_titles_clean_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS titles_clean;\n",
    "\n",
    "CREATE TABLE titles_clean AS\n",
    "SELECT\n",
    "    show_id,\n",
    "    lower(trim(type)) AS type,\n",
    "    lower(trim(title)) AS title,\n",
    "    lower(trim(director)) AS director,\n",
    "    lower(trim(\"cast\")) AS \"cast\",\n",
    "    CASE\n",
    "        WHEN country IS NULL OR trim(country) = '' THEN 'unknown'\n",
    "        ELSE lower(trim(country))\n",
    "    END AS country,\n",
    "    CASE\n",
    "        WHEN date_added IS NOT NULL AND length(trim(date_added)) > 0\n",
    "        THEN date(\n",
    "            substr(date_added, -4) || '-' ||\n",
    "            printf('%02d',\n",
    "                (instr('JanFebMarAprMayJunJulAugSepOctNovDec',\n",
    "                       substr(date_added, 1, 3)) + 2) / 3\n",
    "            ) || '-' ||\n",
    "            printf('%02d', CAST(replace(substr(date_added, instr(date_added, ' ')+1), ',', '') AS INT))\n",
    "        )\n",
    "        ELSE NULL\n",
    "    END AS date_added,\n",
    "    CAST(release_year AS INTEGER) AS release_year,\n",
    "    CASE\n",
    "        WHEN rating IS NULL OR trim(rating) = '' THEN 'not_rated'\n",
    "        ELSE lower(trim(rating))\n",
    "    END AS rating,\n",
    "    lower(trim(duration)) AS duration,\n",
    "    CASE\n",
    "        WHEN lower(duration) LIKE '%min%' THEN CAST(replace(lower(duration), 'min', '') AS INT)\n",
    "        WHEN lower(duration) LIKE '%season%' THEN CAST(replace(replace(lower(duration), 'seasons', ''), 'season', '') AS INT)\n",
    "        ELSE NULL\n",
    "    END AS duration_value,\n",
    "    CASE\n",
    "        WHEN lower(duration) LIKE '%min%' THEN 'min'\n",
    "        WHEN lower(duration) LIKE '%season%' THEN 'season'\n",
    "        ELSE NULL\n",
    "    END AS duration_unit,\n",
    "    lower(trim(listed_in)) AS listed_in,\n",
    "    lower(trim(description)) AS description\n",
    "FROM titles_raw;\n",
    "\"\"\"\n",
    "conn.executescript(create_titles_clean_sql)\n",
    "print(\"titles_clean criada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f905f",
   "metadata": {},
   "source": [
    " Explosão da coluna multivalor country para titles_by_country\n",
    " country vem como uma string com países separados por vírgula (ex.: \"Brazil, United States\").\n",
    " Para contar e cruzar corretamente, eu explodo em linhas: um show_id para cada país.\n",
    "\n",
    " Como faço isso no SQLite:\n",
    " - Transformo a string em um array JSON de países.\n",
    " - Uso json_each(...) (extensão JSON do SQLite) para \"iterar\" pelos elementos.\n",
    " - Faço trim e lower para padronizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adaa7b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles_by_country criada com 10843 linhas\n"
     ]
    }
   ],
   "source": [
    "create_by_country_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS titles_by_country;\n",
    "\n",
    "CREATE TABLE titles_by_country AS\n",
    "WITH exploded AS (\n",
    "    SELECT\n",
    "        show_id,\n",
    "        trim(value) AS country\n",
    "    FROM titles_clean,\n",
    "         json_each('[\"' || replace(ifnull(country,''), ',', '\",\"') || '\"]')\n",
    "    WHERE trim(value) <> ''\n",
    ")\n",
    "SELECT show_id, lower(country) AS country\n",
    "FROM exploded;\n",
    "\"\"\"\n",
    "\n",
    "conn.executescript(create_by_country_sql)\n",
    "\n",
    "# Validação\n",
    "count_countries = conn.execute(\"SELECT COUNT(*) FROM titles_by_country;\").fetchone()[0]\n",
    "print(f\"titles_by_country criada com {count_countries} linhas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e9f03",
   "metadata": {},
   "source": [
    "Explosão da coluna multivalor listed_in (gêneros) para titles_by_genre\n",
    " Mesma ideia da coluna country, mas agora para gêneros. Cada gênero vira uma linha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e86eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles_by_genre criada com 19323 linhas\n"
     ]
    }
   ],
   "source": [
    "create_by_genre_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS titles_by_genre;\n",
    "\n",
    "CREATE TABLE titles_by_genre AS\n",
    "WITH exploded AS (\n",
    "    SELECT\n",
    "        show_id,\n",
    "        trim(value) AS genre\n",
    "    FROM titles_clean,\n",
    "         json_each('[\"' || replace(ifnull(listed_in,''), ',', '\",\"') || '\"]')\n",
    "    WHERE trim(value) <> ''\n",
    ")\n",
    "SELECT show_id, lower(genre) AS genre\n",
    "FROM exploded;\n",
    "\"\"\"\n",
    "\n",
    "conn.executescript(create_by_genre_sql)\n",
    "\n",
    "# Validação\n",
    "count_genres = conn.execute(\"SELECT COUNT(*) FROM titles_by_genre;\").fetchone()[0]\n",
    "print(f\"titles_by_genre criada com {count_genres} linhas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc6d80",
   "metadata": {},
   "source": [
    " Índices para acelerar consultas\n",
    " Índices deixam filtros, joins e ordenações muito mais rápidos nas colunas mais usadas.\n",
    " Aqui eu crio índices em:\n",
    " - show_id, type, date_added na base limpa.\n",
    " - country e genre nas tabelas explodidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f69837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices criados.\n"
     ]
    }
   ],
   "source": [
    "conn.executescript(\"\"\"\n",
    "CREATE INDEX IF NOT EXISTS ix_titles_clean_show_id ON titles_clean(show_id);\n",
    "CREATE INDEX IF NOT EXISTS ix_titles_clean_type ON titles_clean(type);\n",
    "CREATE INDEX IF NOT EXISTS ix_titles_clean_date_added ON titles_clean(date_added);\n",
    "CREATE INDEX IF NOT EXISTS ix_titles_by_country_country ON titles_by_country(country);\n",
    "CREATE INDEX IF NOT EXISTS ix_titles_by_genre_genre ON titles_by_genre(genre);\n",
    "\"\"\")\n",
    "print(\"Índices criados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc02d5",
   "metadata": {},
   "source": [
    "Exportar tabelas tratadas para data/processed\n",
    " Exporto as três tabelas para **Parquet** (formato compactado e rápido).\n",
    " Vantagens do Parquet:\n",
    " - Colunar (ótimo para leitura seletiva de colunas).\n",
    " - Compacto (economiza espaço)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f5d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: C:\\Users\\maria\\OneDrive\\Documentos\\Portifolio-dados\\netflix-analytics\\data\\processed\\titles_clean.parquet\n",
      "Exportado: C:\\Users\\maria\\OneDrive\\Documentos\\Portifolio-dados\\netflix-analytics\\data\\processed\\titles_by_country.parquet\n",
      "Exportado: C:\\Users\\maria\\OneDrive\\Documentos\\Portifolio-dados\\netflix-analytics\\data\\processed\\titles_by_genre.parquet\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"titles_clean\": \"SELECT * FROM titles_clean;\",\n",
    "    \"titles_by_country\": \"SELECT * FROM titles_by_country;\",\n",
    "    \"titles_by_genre\": \"SELECT * FROM titles_by_genre;\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    for name, query in tables.items():\n",
    "        df_out = pd.read_sql_query(query, conn)\n",
    "        pq_path = PROC_DIR / f\"{name}.parquet\"\n",
    "        df_out.to_parquet(pq_path, index=False)\n",
    "        print(f\"Exportado: {pq_path}\")\n",
    "except Exception as e:\n",
    "    print(\"Parquet não exportado\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520089c3",
   "metadata": {},
   "source": [
    "Encerramento da etapa de tratamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03d7183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tratamento concluído com sucesso\n"
     ]
    }
   ],
   "source": [
    "conn.close()\n",
    "print(\"Tratamento concluído com sucesso\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
